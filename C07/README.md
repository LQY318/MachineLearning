horse_ada.py
(1) 收集数据:提供的文本文件。data/文件夹中
(2) 准备数据:确保类别标签是+1和-1而非1和0。
(3) 分析数据:手工检查数据。
(4) 训练算法:在数据上,利用train_AB() 函数训练出一系列的分类器。 
(5) 测试算法:我们拥有两个数据集。利用classifier_AB()函数进行分类。
(6) 使用算法:观察该例子上的错误率。
AdaBoost：
1.训练过程中，每次迭代都添加一个弱分类器，直至错误率为0或者超过最大迭代次数，结束训练
2.每次迭代的预测值都是对当前所有弱分类器的预测结果的加权和，顺序应用多个弱分类器
3.注意过拟合现象
4.D用于调节对样本的权重，alpha用于调节对弱分类器的权重
5.对错误具有调节能力
非均衡分类问题（正例和反例样本数目差距大、错分正例和反例的代价不一样）：
除了错误率，还可以考虑如下问题
1.混淆矩阵
2.准确率、召回率ROC曲线
3.代价矩阵
疑问：
1.adaboost.py中train_Ada函数中更新D的计算方式有疑问？
2.adaboost.py中create_stump函数中的错误率计算有疑问？
3.horse_ada.py中plotROC函数的x、y步长的计算方式有疑问？
4.horse_ada.py中plotROC函数中计算每个x、y的方式还搞不懂？